{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "sharp-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "protected-hours",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69, 51)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FNC40</th>\n",
       "      <th>FNC33</th>\n",
       "      <th>FNC20</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map36</th>\n",
       "      <th>SBM_map17</th>\n",
       "      <th>FNC48</th>\n",
       "      <th>FNC37</th>\n",
       "      <th>FNC353</th>\n",
       "      <th>...</th>\n",
       "      <th>FNC289</th>\n",
       "      <th>FNC285</th>\n",
       "      <th>FNC278</th>\n",
       "      <th>FNC275</th>\n",
       "      <th>FNC23</th>\n",
       "      <th>FNC213</th>\n",
       "      <th>FNC211</th>\n",
       "      <th>FNC210</th>\n",
       "      <th>FNC177</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.042770</td>\n",
       "      <td>0.21967</td>\n",
       "      <td>0.023462</td>\n",
       "      <td>-0.553621</td>\n",
       "      <td>-0.048894</td>\n",
       "      <td>-0.666222</td>\n",
       "      <td>0.393087</td>\n",
       "      <td>-0.16328</td>\n",
       "      <td>-0.068833</td>\n",
       "      <td>-0.020897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>-0.25555</td>\n",
       "      <td>-0.22028</td>\n",
       "      <td>0.091184</td>\n",
       "      <td>-0.189860</td>\n",
       "      <td>0.094641</td>\n",
       "      <td>0.45274</td>\n",
       "      <td>0.350390</td>\n",
       "      <td>-0.012638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026720</td>\n",
       "      <td>0.82281</td>\n",
       "      <td>-0.146650</td>\n",
       "      <td>-0.300549</td>\n",
       "      <td>-0.030364</td>\n",
       "      <td>-0.336090</td>\n",
       "      <td>0.964257</td>\n",
       "      <td>0.71657</td>\n",
       "      <td>0.447540</td>\n",
       "      <td>-0.227980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469910</td>\n",
       "      <td>-0.36558</td>\n",
       "      <td>-0.49325</td>\n",
       "      <td>0.013791</td>\n",
       "      <td>0.561350</td>\n",
       "      <td>0.083160</td>\n",
       "      <td>0.48699</td>\n",
       "      <td>0.723200</td>\n",
       "      <td>-0.000896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.081407</td>\n",
       "      <td>0.44264</td>\n",
       "      <td>0.012487</td>\n",
       "      <td>-0.081175</td>\n",
       "      <td>1.332840</td>\n",
       "      <td>1.172378</td>\n",
       "      <td>-1.050905</td>\n",
       "      <td>0.60398</td>\n",
       "      <td>-0.169190</td>\n",
       "      <td>-0.252030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020654</td>\n",
       "      <td>-0.15788</td>\n",
       "      <td>0.39020</td>\n",
       "      <td>0.213510</td>\n",
       "      <td>-0.090663</td>\n",
       "      <td>0.326170</td>\n",
       "      <td>-0.18757</td>\n",
       "      <td>0.390630</td>\n",
       "      <td>-0.111880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.365520</td>\n",
       "      <td>0.21516</td>\n",
       "      <td>0.195540</td>\n",
       "      <td>0.220316</td>\n",
       "      <td>-0.982331</td>\n",
       "      <td>-1.062109</td>\n",
       "      <td>0.137624</td>\n",
       "      <td>0.22927</td>\n",
       "      <td>-0.086613</td>\n",
       "      <td>-0.230490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465930</td>\n",
       "      <td>-0.11343</td>\n",
       "      <td>-0.18818</td>\n",
       "      <td>-0.023861</td>\n",
       "      <td>0.338460</td>\n",
       "      <td>0.407870</td>\n",
       "      <td>0.28285</td>\n",
       "      <td>0.231020</td>\n",
       "      <td>0.126880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.054571</td>\n",
       "      <td>0.47644</td>\n",
       "      <td>0.506320</td>\n",
       "      <td>-0.370420</td>\n",
       "      <td>0.313340</td>\n",
       "      <td>0.212350</td>\n",
       "      <td>1.952477</td>\n",
       "      <td>-0.33573</td>\n",
       "      <td>0.198670</td>\n",
       "      <td>-0.266090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362940</td>\n",
       "      <td>-0.44335</td>\n",
       "      <td>0.13523</td>\n",
       "      <td>0.221310</td>\n",
       "      <td>-0.044503</td>\n",
       "      <td>0.021357</td>\n",
       "      <td>0.37870</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.079035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FNC40    FNC33     FNC20  SBM_map67  SBM_map61  SBM_map36  SBM_map17  \\\n",
       "0 -0.042770  0.21967  0.023462  -0.553621  -0.048894  -0.666222   0.393087   \n",
       "1  0.026720  0.82281 -0.146650  -0.300549  -0.030364  -0.336090   0.964257   \n",
       "2 -0.081407  0.44264  0.012487  -0.081175   1.332840   1.172378  -1.050905   \n",
       "3 -0.365520  0.21516  0.195540   0.220316  -0.982331  -1.062109   0.137624   \n",
       "4 -0.054571  0.47644  0.506320  -0.370420   0.313340   0.212350   1.952477   \n",
       "\n",
       "     FNC48     FNC37    FNC353  ...    FNC289   FNC285   FNC278    FNC275  \\\n",
       "0 -0.16328 -0.068833 -0.020897  ...  0.003765 -0.25555 -0.22028  0.091184   \n",
       "1  0.71657  0.447540 -0.227980  ...  0.469910 -0.36558 -0.49325  0.013791   \n",
       "2  0.60398 -0.169190 -0.252030  ...  0.020654 -0.15788  0.39020  0.213510   \n",
       "3  0.22927 -0.086613 -0.230490  ...  0.465930 -0.11343 -0.18818 -0.023861   \n",
       "4 -0.33573  0.198670 -0.266090  ...  0.362940 -0.44335  0.13523  0.221310   \n",
       "\n",
       "      FNC23    FNC213   FNC211    FNC210    FNC177  Class  \n",
       "0 -0.189860  0.094641  0.45274  0.350390 -0.012638      1  \n",
       "1  0.561350  0.083160  0.48699  0.723200 -0.000896      0  \n",
       "2 -0.090663  0.326170 -0.18757  0.390630 -0.111880      1  \n",
       "3  0.338460  0.407870  0.28285  0.231020  0.126880      1  \n",
       "4 -0.044503  0.021357  0.37870  0.004384  0.079035      1  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/Users/zarreennaowalreza/Desktop/openmined/PPMH/schrizofrenia_tab_data/final_train_50.csv')\n",
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "knowing-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 50\n",
    "out_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fixed-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicalLR(torch.nn.Module):\n",
    "    def __init__(self, torch):\n",
    "        super(ClassicalLR, self).__init__()\n",
    "        self.layer1 = torch.nn.Linear(in_dim, 20)\n",
    "        self.layer2 = torch.nn.Linear(20, 30)\n",
    "        self.out = torch.nn.Linear(30, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.layer1(x))\n",
    "        x = torch.nn.functional.relu(self.layer2(x))\n",
    "        output = torch.nn.functional.log_softmax(self.out(x), dim=1) \n",
    "        return output\n",
    "    \n",
    "classical_model = ClassicalLR(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "incorporate-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.loc[:, train_data.columns != 'Class']\n",
    "y_train = train_data['Class']\n",
    "\n",
    "X_train = torch.FloatTensor(np.array(X_train))\n",
    "y_train = torch.LongTensor(np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "foreign-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_train(iterations, model, torch, optim, data, target, criterion):\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss_item = loss.item()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"Epoch\", i, \"loss\", loss_item)\n",
    "        \n",
    "        losses.append(loss_item)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optim.step()\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "chinese-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = classical_model.parameters()\n",
    "optim = torch.optim.Adam(params=params, lr=0.1)\n",
    "criterion = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "nominated-garlic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 0.6984010338783264\n",
      "Epoch 10 loss 0.00032507238211110234\n",
      "Epoch 20 loss 4.502453521126881e-05\n",
      "Epoch 30 loss 1.0748902241175529e-05\n",
      "Epoch 40 loss 1.0766014383989386e-05\n",
      "Epoch 50 loss 8.073785465967376e-06\n",
      "Epoch 60 loss 5.76807633478893e-06\n",
      "Epoch 70 loss 4.365503627923317e-06\n",
      "Epoch 80 loss 3.501799483274226e-06\n",
      "Epoch 90 loss 2.93173343379749e-06\n"
     ]
    }
   ],
   "source": [
    "iteration = 100\n",
    "losses = classic_train(iteration, classical_model, torch, optim, X_train, y_train, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "differential-institution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'iteration')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(iteration), losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eight-hawaii",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 51)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FNC40</th>\n",
       "      <th>FNC33</th>\n",
       "      <th>FNC20</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map36</th>\n",
       "      <th>SBM_map17</th>\n",
       "      <th>FNC48</th>\n",
       "      <th>FNC37</th>\n",
       "      <th>FNC353</th>\n",
       "      <th>...</th>\n",
       "      <th>FNC289</th>\n",
       "      <th>FNC285</th>\n",
       "      <th>FNC278</th>\n",
       "      <th>FNC275</th>\n",
       "      <th>FNC23</th>\n",
       "      <th>FNC213</th>\n",
       "      <th>FNC211</th>\n",
       "      <th>FNC210</th>\n",
       "      <th>FNC177</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.34404</td>\n",
       "      <td>0.64302</td>\n",
       "      <td>0.148900</td>\n",
       "      <td>-0.791032</td>\n",
       "      <td>0.829697</td>\n",
       "      <td>-0.026555</td>\n",
       "      <td>0.187573</td>\n",
       "      <td>0.515280</td>\n",
       "      <td>0.485810</td>\n",
       "      <td>0.273290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116160</td>\n",
       "      <td>0.11131</td>\n",
       "      <td>-0.14180</td>\n",
       "      <td>0.43596</td>\n",
       "      <td>0.40514</td>\n",
       "      <td>0.49545</td>\n",
       "      <td>0.62594</td>\n",
       "      <td>0.488840</td>\n",
       "      <td>0.15221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.12732</td>\n",
       "      <td>0.25707</td>\n",
       "      <td>0.373060</td>\n",
       "      <td>0.889753</td>\n",
       "      <td>-0.978412</td>\n",
       "      <td>-1.027496</td>\n",
       "      <td>1.961955</td>\n",
       "      <td>0.176950</td>\n",
       "      <td>-0.105510</td>\n",
       "      <td>-0.499290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110400</td>\n",
       "      <td>0.24471</td>\n",
       "      <td>0.16378</td>\n",
       "      <td>0.14387</td>\n",
       "      <td>-0.34615</td>\n",
       "      <td>0.43485</td>\n",
       "      <td>0.21171</td>\n",
       "      <td>-0.177450</td>\n",
       "      <td>0.19885</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.34123</td>\n",
       "      <td>0.66877</td>\n",
       "      <td>0.338740</td>\n",
       "      <td>0.785572</td>\n",
       "      <td>-0.896406</td>\n",
       "      <td>-0.213169</td>\n",
       "      <td>0.313224</td>\n",
       "      <td>0.253410</td>\n",
       "      <td>0.098053</td>\n",
       "      <td>-0.316810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085182</td>\n",
       "      <td>-0.16643</td>\n",
       "      <td>0.26968</td>\n",
       "      <td>0.57360</td>\n",
       "      <td>-0.25904</td>\n",
       "      <td>0.61563</td>\n",
       "      <td>0.55868</td>\n",
       "      <td>0.447560</td>\n",
       "      <td>-0.36652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.24601</td>\n",
       "      <td>0.59077</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-1.522856</td>\n",
       "      <td>1.739382</td>\n",
       "      <td>1.574719</td>\n",
       "      <td>-1.308689</td>\n",
       "      <td>-0.033231</td>\n",
       "      <td>-0.304670</td>\n",
       "      <td>0.500520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078982</td>\n",
       "      <td>-0.51740</td>\n",
       "      <td>-0.57098</td>\n",
       "      <td>0.46945</td>\n",
       "      <td>0.19352</td>\n",
       "      <td>-0.22173</td>\n",
       "      <td>-0.10941</td>\n",
       "      <td>0.336160</td>\n",
       "      <td>-0.13141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.17317</td>\n",
       "      <td>0.51587</td>\n",
       "      <td>0.277670</td>\n",
       "      <td>-0.256770</td>\n",
       "      <td>0.263038</td>\n",
       "      <td>0.833339</td>\n",
       "      <td>-0.051214</td>\n",
       "      <td>0.679640</td>\n",
       "      <td>0.499420</td>\n",
       "      <td>0.083208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194680</td>\n",
       "      <td>0.21828</td>\n",
       "      <td>0.27271</td>\n",
       "      <td>0.37475</td>\n",
       "      <td>0.69264</td>\n",
       "      <td>0.36131</td>\n",
       "      <td>0.14574</td>\n",
       "      <td>0.027857</td>\n",
       "      <td>-0.11404</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FNC40    FNC33     FNC20  SBM_map67  SBM_map61  SBM_map36  SBM_map17  \\\n",
       "0  0.34404  0.64302  0.148900  -0.791032   0.829697  -0.026555   0.187573   \n",
       "1 -0.12732  0.25707  0.373060   0.889753  -0.978412  -1.027496   1.961955   \n",
       "2  0.34123  0.66877  0.338740   0.785572  -0.896406  -0.213169   0.313224   \n",
       "3  0.24601  0.59077 -0.067104  -1.522856   1.739382   1.574719  -1.308689   \n",
       "4 -0.17317  0.51587  0.277670  -0.256770   0.263038   0.833339  -0.051214   \n",
       "\n",
       "      FNC48     FNC37    FNC353  ...    FNC289   FNC285   FNC278   FNC275  \\\n",
       "0  0.515280  0.485810  0.273290  ...  0.116160  0.11131 -0.14180  0.43596   \n",
       "1  0.176950 -0.105510 -0.499290  ...  0.110400  0.24471  0.16378  0.14387   \n",
       "2  0.253410  0.098053 -0.316810  ... -0.085182 -0.16643  0.26968  0.57360   \n",
       "3 -0.033231 -0.304670  0.500520  ...  0.078982 -0.51740 -0.57098  0.46945   \n",
       "4  0.679640  0.499420  0.083208  ...  0.194680  0.21828  0.27271  0.37475   \n",
       "\n",
       "     FNC23   FNC213   FNC211    FNC210   FNC177  Class  \n",
       "0  0.40514  0.49545  0.62594  0.488840  0.15221      0  \n",
       "1 -0.34615  0.43485  0.21171 -0.177450  0.19885      1  \n",
       "2 -0.25904  0.61563  0.55868  0.447560 -0.36652      1  \n",
       "3  0.19352 -0.22173 -0.10941  0.336160 -0.13141      0  \n",
       "4  0.69264  0.36131  0.14574  0.027857 -0.11404      0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('/Users/zarreennaowalreza/Desktop/openmined/PPMH/schrizofrenia_tab_data/final_test_50.csv')\n",
    "print(test_data.shape)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "productive-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.loc[:, test_data.columns != 'Class']\n",
    "y_test = test_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "stopped-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.FloatTensor(np.array(X_test))\n",
    "y_test = torch.LongTensor(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "rolled-bikini",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0 Ground Truth: 0\n",
      "Prediction: 1 Ground Truth: 1\n",
      "Prediction: 1 Ground Truth: 1\n",
      "Prediction: 0 Ground Truth: 0\n",
      "Prediction: 0 Ground Truth: 0\n",
      "Prediction: 0 Ground Truth: 0\n",
      "Prediction: 0 Ground Truth: 0\n",
      "Prediction: 0 Ground Truth: 1\n",
      "Prediction: 1 Ground Truth: 1\n",
      "Prediction: 0 Ground Truth: 0\n",
      "Prediction: 1 Ground Truth: 1\n",
      "Prediction: 1 Ground Truth: 1\n",
      "Prediction: 0 Ground Truth: 1\n",
      "Prediction: 0 Ground Truth: 0\n",
      "Prediction: 0 Ground Truth: 0\n",
      "Prediction: 0 Ground Truth: 0\n",
      "Prediction: 0 Ground Truth: 0\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(X_test)):\n",
    "        sample = X_test[i]\n",
    "        y_hat = classical_model(sample.unsqueeze(0))\n",
    "        pred = y_hat.argmax().item()\n",
    "        print(f\"Prediction: {pred} Ground Truth: {y_test[i]}\")\n",
    "        preds.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-simple",
   "metadata": {},
   "source": [
    "False positive at index 8 and 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "substantial-choir",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall test accuracy 88.23529411764706\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, preds)\n",
    "print(\"Overall test accuracy\", acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-toilet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
